<html>
<head>
<title> Hussain² </title>

</head>
    <!-- <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel="stylesheet"> -->

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
<body style="padding: 25pt;padding-left:25%;padding-right:25%;">
<center>

<!-- <img src='me.jpg'/> -->
<br/> <b> Hussain² </b>
</center>
<br/>

<!-- <p style="background-color:tomato;">  Website is under construction if you didn't notice </p> -->
<p>I'm Hussain Hussain, a third year PhD student at <a href="https://tugraz.at">TU Graz</a> (<a href="https://isds.tugraz.at/">Institute of Interactive Systems and Data Science</a>) and <a href="https://www.know-center.tugraz.at/">Know-Center</a>, supervised by <a href="https://courses.isds.tugraz.at/rkern/about/">Dr. Roman Kern</a>.
</p>
<p>
	I'm mainly interested in graph mining and currently I focus on the impact of network structural properties on the output of graph learning models. See my <a href="Hussain_Resume.pdf">academic CV</a> or the publication list below.
</p>
<p>
Feel free to reach out
	<ul>
		<li><a href="mailto:hussain@tugraz.at">hussain@tugraz.at</a></li>
		<li>Twitter: <a href="https://twitter.com/sqr_hussain">sqr_hussain</a></li>
		<li>Github: <a href="https://github.com/sqrhussain">sqrhussain</a> </li>
	</ul>
</p>
<h3> Publications </h3>
<p align="right"><a href="https://scholar.google.com/citations?user=CEeLGfQAAAAJ&hl=en">[Google Scholar page]</a></p>
<ul>
	<li> <strong>Adversarial Inter-Group Link Injection Degrades the Fairness of Graph Neural Networks</strong>
	<br/>Hussain Hussain, Meng Cao, Sandipan Sikdar, Denis Helic, Elisabeth Lex, Markus Strohmaier, Roman Kern.
	<br/>To appear at IEEE ICDM 2022 as a short paper.
	<!-- <br/><a href="https://doi.org/10.1007/s41109-021-00423-1">https://doi.org/10.1007/s41109-021-00423-1</a> -->
	<br/> <a href="papers/icdm22.pdf">[preprint]</a> <a href="https://github.com/mengcao327/attack-gnn-fairness/">[code]</a>
	</li>
	<li>
		 <strong>Effective Use of BERT in Graph Embeddings for Sparse Knowledge Graph Completion.</strong>
		 <br/> Xinglan Liu, Hussain Hussain, Houssam Razouk, Roman Kern.
		 <br/>ACM SAC'22, 790-793 (2022).
		 <br/> <a href="https://dl.acm.org/doi/10.1145/3477314.3507031"> https://dl.acm.org/doi/10.1145/3477314.3507031 </a>
	</li>
<li> <strong>The interplay between communities and homophily in semi-supervised classification using graph neural networks.</strong>
<br/>H Hussain, T Duricic, E Lex, D Helic, R Kern.
<br/>Applied Network Science 6, 80 (2021).
<br/><a href="https://doi.org/10.1007/s41109-021-00423-1">https://doi.org/10.1007/s41109-021-00423-1</a>
<br/> <a href="papers/apns21.pdf">[preprint]</a> <a href="https://github.com/sqrhussain/homophily-community-gnn">[code]</a>
</li>
<li> <strong>Structack: Structure-based Adversarial Attacks on Graph Neural Networks.</strong>
<br/>H Hussain, T Duricic, E Lex, D Helic, M Strohmaier, R Kern.
<br/>Proceedings of the 32st ACM Conference on Hypertext and Social Media (2021).
<br/> <a href="papers/ht21.pdf">[preprint]</a> <a href="https://github.com/sqrhussain/structack">[code]</a>
</li>
<li>
<strong>Should We Embed in Chemistry? A Comparison of Unsupervised Transfer Learning with PCA, UMAP, and VAE on Molecular Fingerprints</strong>
<br/>Mario Lovrić, Tomislav Đuričić, Han TN Tran, Hussain Hussain, Emanuel Lacić, Morten A Rasmussen, Roman Kern
<br/>Pharmaceuticals 14 (8), 758 (2021).
</li>
<li><strong>On the Impact of Communities on Semi-supervised Classification Using Graph Neural Networks.</strong>
<br/>H Hussain, T Duricic, E Lex, R Kern, D Helic.
<br/>International Conference on Complex Networks and Their Applications, 15-26 (2020).
<br/> <a href="papers/cna20.pdf">[preprint]</a> <a href="https://github.com/sqrhussain/homophily-community-gnn">[code]</a>
</li>
<li><strong>Empirical Comparison of Graph Embeddings for Trust-Based Collaborative Filtering.</strong>
<br/>T Duricic, H Hussain, E Lacic, D Kowald, D Helic, E Lex
<br/>International Symposium on Methodologies for Intelligent Systems, 181-191 (2020).
<br/><a href="https://arxiv.org/abs/2003.13345">[preprint]</a>
</li>
</ul>

<!-- <h3> Open Theses (Bachelor's and Master's) </h3>
<ol>
<li> Fair predictions with graph data.
<p> <b> Motivation. </b>
	Recent works showed that graph data can exacerbate unfairness of predictions. How does this happen? And how can we prevent it?</p>
</li>
<li> Estimating graph homophily for better GNN predictions.
<p> <b> Premise. </b>
	Recent work has shown that classical GNNs work only for homophilic graphs, i.e., graphs where adjacent nodes are more likely to have the same label or similar features. More recently, novel GNN models have been proposed to address this issue and improve the performance on heterophilic graphs. Most node classification approaches follow a semi-supervised learning paradigm, where only a small fraction of nodes is labeled.</p>
<p> <b> Objective. </b>
	Our aim is to estimate (efficiently and accurately) whether a graph is homophilic or heterophilic in semi-supervised settings, aiding to choose a suitable GNN model for the problem.</p>
<p> <b> Methods. </b>
	We test different measures which simulate/estimate homophily and/or predict which type of GNNs to use for a given dataset. We observe the correlation of the measure with the actual homophily.</p>
	We perform these experiments on empirical as well as synthetic graphs.
<p> <b> Impact. </b>
	This work can help practitioners choose suitable GNN models for their node classification tasks.</p>
</li>
<li> Adversarial attack noticeability in dynamic networks.
<p> <b> Premise. </b>
	GNNs suffer (like many deep learning models) from adversarial attacks. Recent works have studied and introduced different types of practical attacks on graph data (injecting/removing nodes/links in a network, changing features of nodes). These studies were mostly accompanied by insights on attack detection (or noticeability). However, the noticeability insights are mostly limited to static network statistics, e.g., degree distribution. In a dynamic environment, nodes, links, and features are changing all the time.</p>
<p> <b> Objective. </b>
	Is it better to measure noticeability through comparing to a dynamic model? If so, we need to introduce a methodology to measure attack noticeability in a realistic scenario where the network grows with new nodes/edges.</p>
<p> <b> Methods. </b>
	Testing noticeability on temporal/dynamic gaphs (graphs with edge timestamps) and on network growth models for static graphs.
	We can look for a suitable network growth model that is better suited to measure attack noticeability.</p>
<p> <b> Impact. </b>
	The findings should help researchers who work on developing GNN attacks to better define their attacks' ability to be unnoticed.
	The findings should also help practitioners (operators of vulnurable network data) to better detect adversarial attacks.</p>
</li>
</ol> -->

<h3> TU Graz Data Team </h3>
<p>Each semester, we participate in data challenges together in the <a href="https://www.tugraz.at/studium/studieren-an-der-tu-graz/studierende/studierendenteams/wettbewerbs-und-fokuste">TU Graz data team</a>.
</p>
<p>
	You can participate in a challenge within the data team as a student project in <a href="https://courses.isds.tugraz.at/rkern/courses/kddm2/">KDDM2 (706.715) VU</a> course in the winter semster or <a href="https://courses.isds.tugraz.at/rkern/courses/nlp/">NLP (706.230) VU</a> course in the summer semster.
</p>
<p>
<a href="https://goo.gl/forms/fOWbptLuZpert5D23">Join us now</a> for some data science, drinks and pizza ;)</p>


<h3> News Timeline </h3>
<h4> Good News </h4>
<ul>
	<li> 22-09-01 - Our paper titled <b>"Adversarial Inter-Group Link Injection Degrades the Fairness of Graph Neural Networks"</b> got accepted at IEEE ICDM 2022. </li>
	<li>21-12-16 - Our paper titled <b>"Effective Use of BERT in Graph Embeddings for Sparse Knowledge Graph Completion"</b> was accepted for publication in ACM SAC '22 conference.</li>
<li> 21-09-07 - Our paper titled <b>"The Interplay between Communities and Homophily in Semi-supervised Classification Using Graph Neural Networks."</b> was accepted at Applied Network Science special issue. <i>This is an extension of the CompNets2020 paper.</i> <a href="papers/apns21.pdf">[preprint]</a> <a href="https://github.com/sqrhussain/homophily-community-gnn">[code]</a> </li>
<li> 21-07-09 - Our paper <b>"Structack: Structure-based Adversarial Attacks on Graph Neural Networks"</b> got accepted at ACM Hypertext 2021. <a href="papers/ht21.pdf">[preprint]</a> <a href="https://github.com/sqrhussain/structack">[code]</a> </li>
<li> 20-09-30 - Our paper <b>"On the Impact of Communities on Semi-supervised Classification Using Graph Neural Networks"</b> got accepted at Complex Networks 2020. <a href="papers/cna20.pdf">[preprint]</a> <a href="https://github.com/sqrhussain/homophily-community-gnn">[code]</a> </li>
</ul>
<h4> Bad News </h4>
<ul>
<li> 22-05-19 - Our paper on fairness attacks on GNNs got rejected at KDD 2022. </li>
<li> 21-09-07 - I created this webpage. </li>
<li> 21-05-16 - Our paper <b>"Structack: Structure-based Adversarial Attacks on Graph Neural Networks"</b> was rejected at ACM SIGKDD 2021. </li>
<li> 20-06-05 - Our paper <b>"On the Impact of Communities and Hubs on Semi-supervised Classification Using Graph Neural Networks"</b> got rejected at ECML-PKDD 2020. </li>
<li> 20-02-28 - Our abstract <b>"Semi-supervised Classification on Directed Graphs"</b> was rejected at ELLIS Workshop on Geometric and Relational Deep Learning 2020.</li>
<li> 19-10-01 - Our paper <b>"Semi-Supervised Classification for Directed Graphs with Bi-Directional Graph Convolutional Networks"</b> was rejected at NeurIPS 2019 Graph Representation Learning workshop.</li>
</ul>


</body>
<footer>


</footer>
</html>
